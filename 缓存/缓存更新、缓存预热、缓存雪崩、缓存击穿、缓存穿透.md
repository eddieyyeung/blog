- [缓存更新](#缓存更新)
  - [Cache aside](#cache-aside)
  - [Read/Write Through Pattern](#readwrite-through-pattern)
  - [Write Behind Caching Pattern](#write-behind-caching-pattern)
- [缓存预热](#缓存预热)
- [缓存雪崩](#缓存雪崩)
- [缓存击穿](#缓存击穿)
- [缓存穿透](#缓存穿透)

## 缓存更新
更新缓存的的 Design Pattern 有四种：Cache aside, Read through, Write through, Write behind caching

### Cache aside
- **失效**：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
- **命中**：应用程序从 cache 中取数据，取到后返回。
- **更新**：先把数据存到数据库中，成功后，再让缓存失效。

![读数据](images/Cache-Aside-Design-Pattern-Flow-Diagram-e1470471723210.png)

![写数据](images/Updating-Data-using-the-Cache-Aside-Pattern-Flow-Diagram-1-e1470471761402.png)

那么，是不是 Cache Aside 这个就不会有并发问题了？不是的，比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。

但，这个 case 理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。

### Read/Write Through Pattern
更新数据库的操作由缓存自己代理。缓存未命中时由缓存加载数据库数据然后应用从缓存读，写数据时更新完缓存后同步写数据库。应用只感知缓存而不感知数据库。

- **Read Through**
  Read Through 套路就是在查询操作中更新缓存，也就是说，当缓存失效的时候（过期或 LRU 换出），Cache Aside 是由调用方负责把数据加载入缓存，而 Read Through 则用缓存服务自己来加载，从而对应用方是透明的。
- **Write Through**
  Write Through 套路和 Read Through 相仿，不过是在更新数据时发生。当有数据更新的时候，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，然后再由 Cache 自己更新数据库（这是一个同步操作）

![Read/Write Through Pattern](images/460px-Write-through_with_no-write-allocation.svg_.png)

### Write Behind Caching Pattern
在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。
这个设计的好处就是让数据的 I/O 操作飞快无比（因为直接操作内存嘛 ），因为异步，write backg 还可以合并对同一个数据的多次操作，所以性能的提高是相当可观的。
但是，其带来的问题是，数据不是强一致性的，而且可能会丢失数据。

![Write Behind Caching Pattern](images/Write-back_with_write-allocation.png)

## 缓存预热
**原因**：
当服务刚启动的时候，缓存中没有数据，那么就会大量并发访问数据库，也会瞬间产生大量的缓存数据，如果是采用主从缓存的架构，那么主从之间同步的频率和吞吐量也会增加，会对后端服务、数据库、缓存服务器造成负载压力过大，从而使服务不可用。

**解决方案**：
- 提前统计热点数据，然后批量加载到 redis 缓存服务器中
  实践方法：
  - nginx 将访问日志流量上报到 kafka
  - storm 从 kafka 中消费数据，实时统计访问次数
  - 每个 storm task 中采用 LRU 算法维护 top n 的热点数据，然后定时同步到 zk 中
  - 通过一个服务，根据 top n 列表在 mysql 中获取数据缓存到 redis 中

## 缓存雪崩
**原因**：
当某一时刻发生大规模的缓存失效的情况。比如缓存服务宕机了。

**解决方案**：
- **使用集群缓存，保证缓存服务的高可用**
  这种方案就是在发生雪崩前对缓存集群实现高可用，如果是使用 Redis，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。
- **页面静态化处理**
  一旦使用了页面静态化，客户端的数据就不用从缓存中获取了，这样可以减轻缓存的压力，缺点是数据更新不及时。
- **构建多级缓存**
  构建多级缓存可以给每一级的缓存提供更多的数据保障，比如在 redis 和 mysql 数据库中间再加上一层 ehcache 缓存，当缓存中大量 key 过期时，ehcache 缓存可以替 mysql 数据库暂时抵挡一部分流量。构建多级缓存会增加系统的复杂性。
- **限流、降级**
  使用 Hystrix 进行限流 & 降级，这是从客户端的角度来考虑，牺牲一部分客户体验，限制一些客户端请求，能有效的降低应用服务器的压力。待系统平稳运行后再逐渐恢复。
- **开启 redis 持久化机制，尽快恢复缓存集群**
  一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。
- **优化 mysql**
  比如给 mysql 增加 buffer pool,这样当大量流量到达 mysql 时，mysql 的吞吐量可以支撑并发，不至于马上崩溃，也能防止雪崩现象发生。
- **监控 redis 的性能指标**
  根据分析我们知道，“雪崩”伴随着的肯定CPU占用率急剧上升，同时客户端请求的平均响应时间也会增大，对这些性能指标进行监控能帮助我们更早的发现问题。
- **采用 LFU 缓存策略**
- **根据业务数据将缓存的有效期错峰**
  数据的过期时间采用固定时间 + 随机时间戳的方式，稀释集中到期 key 的数量

## 缓存击穿
**原因**：
热点数据集中失效问题。大量的请求同时查询一个 key 时，此时这个 key 正好失效了，就会导致大量的请求都打到数据库上面去。

**造成什么问题**：
会造成某一时刻数据库请求量过大，压力剧增。

**解决方案**：
- **互斥锁**。
  可以在第一个查询数据的请求上使用一个互斥锁来锁住它。其他的线程走到这一步拿不到锁就等着，等第一个线程查询到了数据，然后做缓存。后面的线程进来发现已经有缓存了，就直接走缓存。
- **LFU 缓存策略**
- **根据业务数据将缓存的有效期错峰**
  数据的过期时间采用固定时间 + 随机时间戳的方式，稀释集中到期 key 的数量

## 缓存穿透
**原因**：
请求去查询一条数据库中根本就不存在的数据，也就是缓存和数据库都查询不到这条数据，但是请求每次都会打到数据库上面去。
会被黑客利用，目的是为了拖垮我们的服务器。

**造成什么现象**：
系统平稳运行时，有了突发流量，Redis 缓存的命中率开始下降，内存并没有什么异常，但是 CPU 开始激增，数据库访问也开始激增，直到数据库崩溃。

**解决方案**：
- **布隆过滤器**
- **将不存在的 key 也设置缓存，设置较为短期的过期时间**

---
> 参考资料：
- https://coolshell.cn/articles/17416.html
- https://juejin.im/post/5af5b2c36fb9a07ac65318bd
- https://juejin.im/post/5c9a67ac6fb9a070cb24bf34#heading-3
- https://juejin.im/post/5e9ad171518825738f2b30de#heading-24